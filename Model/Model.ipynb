{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "yQZmpiZg6fOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Define LSTM model architecture\n",
        "def create_lstm_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        LSTM(128, input_shape=input_shape, return_sequences=True),\n",
        "        Dropout(0.2),\n",
        "        LSTM(128),\n",
        "        Dropout(0.2),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "# Assume X_train, y_train, X_val, y_val are your training and validation data\n",
        "\n",
        "# Define model parameters\n",
        "input_shape = (X_train.shape[1], X_train.shape[2])  # Input shape (time steps, features)\n",
        "num_classes = len(set(y_train))  # Number of output classes\n",
        "\n",
        "# Create and compile the LSTM model\n",
        "model = create_lstm_model(input_shape, num_classes)\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    batch_size=64,\n",
        "                    epochs=20,\n",
        "                    verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_val, y_val)\n",
        "print(f'Validation Loss: {loss:.4f}, Validation Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Save the trained model\n",
        "model.save('sign_language_model.h5')\n"
      ],
      "metadata": {
        "id": "udDo7X6I6jJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN"
      ],
      "metadata": {
        "id": "dK0tsj6e6zPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Define CNN model architecture\n",
        "def create_cnn_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dropout(0.5),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "# Assume X_train, y_train, X_val, y_val are your training and validation data\n",
        "\n",
        "# Define model parameters\n",
        "input_shape = X_train.shape[1:]  # Input shape (height, width, channels)\n",
        "num_classes = len(set(y_train))  # Number of output classes\n",
        "\n",
        "# Preprocess the data if necessary (e.g., normalization)\n",
        "\n",
        "# Reshape the input data to match CNN input shape\n",
        "X_train = X_train.reshape(-1, input_shape[0], input_shape[1], input_shape[2])\n",
        "X_val = X_val.reshape(-1, input_shape[0], input_shape[1], input_shape[2])\n",
        "\n",
        "# Create and compile the CNN model\n",
        "model = create_cnn_model(input_shape, num_classes)\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    batch_size=64,\n",
        "                    epochs=20,\n",
        "                    verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_val, y_val)\n",
        "print(f'Validation Loss: {loss:.4f}, Validation Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Save the trained model\n",
        "model.save('sign_language_cnn_model.h5')"
      ],
      "metadata": {
        "id": "xvIKjHGQ60Zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNN"
      ],
      "metadata": {
        "id": "SYNR80Cg7BGG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FDXiPfif7CMN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}